"use strict";(self.webpackChunkphysical_ai_textbook=self.webpackChunkphysical_ai_textbook||[]).push([[9],{7021:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>a,metadata:()=>s,toc:()=>c});var i=t(4848),o=t(8453);const a={id:"chapter10",sidebar_position:5,title:"Isaac Sim Integration \u2013 Validation & Performance Optimization"},r="Chapter 10: Isaac Sim Integration \u2013 Validation & Performance Optimization",s={id:"module2/chapter10",title:"Isaac Sim Integration \u2013 Validation & Performance Optimization",description:"Learning Objectives",source:"@site/docs/module2/chapter10.mdx",sourceDirName:"module2",slug:"/module2/chapter10",permalink:"/docs/module2/chapter10",draft:!1,unlisted:!1,editUrl:"https://github.com/your-github-username/physical-ai-textbook/tree/main/docs/module2/chapter10.mdx",tags:[],version:"current",sidebarPosition:5,frontMatter:{id:"chapter10",sidebar_position:5,title:"Isaac Sim Integration \u2013 Validation & Performance Optimization"}},l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"10.1 Simulation Validation Methodologies",id:"101-simulation-validation-methodologies",level:2},{value:"10.1.1 Kinematic Validation",id:"1011-kinematic-validation",level:3},{value:"10.1.2 Dynamic Validation",id:"1012-dynamic-validation",level:3},{value:"10.2 Performance Optimization Techniques",id:"102-performance-optimization-techniques",level:2},{value:"10.2.1 Simulation Performance Profiling",id:"1021-simulation-performance-profiling",level:3}];function _(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.h1,{id:"chapter-10-isaac-sim-integration--validation--performance-optimization",children:"Chapter 10: Isaac Sim Integration \u2013 Validation & Performance Optimization"}),"\n",(0,i.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(e.p,{children:"By the end of this chapter, students will be able to:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Validate Isaac Sim environments against real-world conditions"}),"\n",(0,i.jsx)(e.li,{children:"Optimize simulation performance for training and deployment"}),"\n",(0,i.jsx)(e.li,{children:"Benchmark simulation accuracy and performance metrics"}),"\n",(0,i.jsx)(e.li,{children:"Debug common Isaac Sim integration issues"}),"\n",(0,i.jsx)(e.li,{children:"Deploy optimized Isaac Sim environments for humanoid robotics"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"101-simulation-validation-methodologies",children:"10.1 Simulation Validation Methodologies"}),"\n",(0,i.jsx)(e.p,{children:"Validating Isaac Sim environments is crucial for ensuring sim-to-real transfer effectiveness. For humanoid robotics, validation must cover multiple aspects:"}),"\n",(0,i.jsx)(e.h3,{id:"1011-kinematic-validation",children:"10.1.1 Kinematic Validation"}),"\n",(0,i.jsx)(e.p,{children:"Kinematic validation ensures that robot movements in simulation match real-world kinematics:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Kinematic validation for humanoid robots\nclass KinematicValidator:\n    """Validate kinematic behavior between simulation and real robot"""\n\n    def __init__(self, robot_model):\n        self.robot_model = robot_model\n        self.validation_metrics = {\n            "position_accuracy": 0.0,    # Position error threshold (m)\n            "orientation_accuracy": 0.0, # Orientation error threshold (rad)\n            "joint_angle_accuracy": 0.0, # Joint angle error threshold (rad)\n            "ik_solution_accuracy": 0.0  # IK solution error threshold\n        }\n\n    def validate_forward_kinematics(self, joint_angles, expected_end_effector_pose, tolerance=0.01):\n        """\n        Validate forward kinematics between sim and real robot\n        """\n        # Compute FK in simulation\n        sim_pose = self.robot_model.compute_forward_kinematics(joint_angles)\n\n        # Compare with expected pose\n        position_error = np.linalg.norm(sim_pose[:3] - expected_end_effector_pose[:3])\n        orientation_error = self._compute_orientation_error(sim_pose[3:], expected_end_effector_pose[3:])\n\n        # Validate within tolerance\n        position_valid = position_error < tolerance\n        orientation_valid = orientation_error < tolerance\n\n        return {\n            "valid": position_valid and orientation_valid,\n            "position_error": position_error,\n            "orientation_error": orientation_error,\n            "position_valid": position_valid,\n            "orientation_valid": orientation_valid\n        }\n\n    def validate_inverse_kinematics(self, target_pose, initial_guess, tolerance=0.01):\n        """\n        Validate inverse kinematics solutions\n        """\n        # Solve IK in simulation\n        sim_joint_angles = self.robot_model.solve_inverse_kinematics(target_pose, initial_guess)\n\n        # Compute forward kinematics of solution\n        computed_pose = self.robot_model.compute_forward_kinematics(sim_joint_angles)\n\n        # Check solution accuracy\n        position_error = np.linalg.norm(computed_pose[:3] - target_pose[:3])\n        orientation_error = self._compute_orientation_error(computed_pose[3:], target_pose[3:])\n\n        solution_valid = position_error < tolerance and orientation_error < tolerance\n\n        return {\n            "solution_valid": solution_valid,\n            "joint_angles": sim_joint_angles,\n            "computed_pose": computed_pose,\n            "position_error": position_error,\n            "orientation_error": orientation_error\n        }\n\n    def _compute_orientation_error(self, quat1, quat2):\n        """Compute orientation error between two quaternions"""\n        # Convert quaternions to rotation matrices\n        rot1 = self._quaternion_to_rotation_matrix(quat1)\n        rot2 = self._quaternion_to_rotation_matrix(quat2)\n\n        # Compute relative rotation\n        rel_rot = np.dot(rot1.T, rot2)\n\n        # Compute angle from rotation matrix\n        trace = np.trace(rel_rot)\n        angle = np.arccos(np.clip((trace - 1) / 2, -1, 1))\n\n        return angle\n\n    def _quaternion_to_rotation_matrix(self, quat):\n        """Convert quaternion to rotation matrix"""\n        w, x, y, z = quat\n        return np.array([\n            [1 - 2*(y*y + z*z), 2*(x*y - w*z), 2*(x*z + w*y)],\n            [2*(x*y + w*z), 1 - 2*(x*x + z*z), 2*(y*z - w*x)],\n            [2*(x*z - w*y), 2*(y*z + w*x), 1 - 2*(x*x + y*y)]\n        ])\n\n    def run_comprehensive_kinematic_validation(self, test_cases):\n        """\n        Run comprehensive kinematic validation with multiple test cases\n        """\n        results = {\n            "fk_validation": [],\n            "ik_validation": [],\n            "overall_accuracy": 0.0,\n            "failure_cases": []\n        }\n\n        total_cases = len(test_cases)\n        successful_cases = 0\n\n        for i, test_case in enumerate(test_cases):\n            if test_case["type"] == "forward_kinematics":\n                result = self.validate_forward_kinematics(\n                    test_case["joint_angles"],\n                    test_case["expected_pose"],\n                    test_case.get("tolerance", 0.01)\n                )\n                results["fk_validation"].append(result)\n            elif test_case["type"] == "inverse_kinematics":\n                result = self.validate_inverse_kinematics(\n                    test_case["target_pose"],\n                    test_case["initial_guess"],\n                    test_case.get("tolerance", 0.01)\n                )\n                results["ik_validation"].append(result)\n\n            if result["valid"] or result.get("solution_valid", False):\n                successful_cases += 1\n            else:\n                results["failure_cases"].append({\n                    "case_index": i,\n                    "case_type": test_case["type"],\n                    "errors": result\n                })\n\n        results["overall_accuracy"] = successful_cases / total_cases if total_cases > 0 else 0.0\n\n        return results\n'})}),"\n",(0,i.jsx)(e.h3,{id:"1012-dynamic-validation",children:"10.1.2 Dynamic Validation"}),"\n",(0,i.jsx)(e.p,{children:"Dynamic validation ensures that robot dynamics in simulation match real-world behavior:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Dynamic validation for humanoid locomotion\ndynamic_validation_config = {\n    "balance_validation": {\n        "zmp_tracking": {\n            "acceptable_error": 0.05,      # meters\n            "tracking_accuracy": 0.95,     # percentage\n            "com_stability": 0.02          # CoM deviation threshold\n        },\n        "capture_point_validation": {\n            "prediction_accuracy": 0.90,    # percentage\n            "step_timing_accuracy": 0.05,   # seconds\n            "step_position_accuracy": 0.05  # meters\n        },\n        "ankle_strategy_validation": {\n            "ankle_torque_limit": 50.0,     # Nm\n            "ankle_angle_limit": 0.3,       # radians\n            "response_time": 0.1            # seconds\n        }\n    },\n    "locomotion_validation": {\n        "walking_stability": {\n            "max_roll_angle": 0.1,          # radians\n            "max_pitch_angle": 0.15,        # radians\n            "step_success_rate": 0.95,      # percentage\n            "walking_speed_accuracy": 0.1    # m/s\n        },\n        "turning_accuracy": {\n            "heading_error": 0.1,           # radians\n            "turning_radius_accuracy": 0.2, # meters\n            "angular_velocity_tracking": 0.9 # percentage\n        },\n        "terrain_adaptation": {\n            "step_height_accuracy": 0.02,    # meters\n            "ground_incline_compensation": 0.1, # radians\n            "obstacle_avoidance_success": 0.95 # percentage\n        }\n    },\n    "manipulation_validation": {\n        "grasp_success_rate": 0.90,         # percentage\n        "object_manipulation_accuracy": 0.01, # meters\n        "end_effector_force_control": 5.0,  # Newtons\n        "dexterous_manipulation_success": 0.85 # percentage\n    }\n}\n\n# Implementation of dynamic validation\nclass DynamicValidator:\n    """Validate dynamic behavior of humanoid robots in Isaac Sim"""\n\n    def __init__(self, config):\n        self.config = config\n        self.validation_history = []\n\n    def validate_balance_stability(self, robot_state, environment_state):\n        """Validate balance stability during locomotion"""\n        # Calculate Zero-Moment Point (ZMP)\n        zmp = self._compute_zmp(robot_state)\n\n        # Calculate Center of Pressure (CoP)\n        cop = self._compute_cop(robot_state, environment_state)\n\n        # Calculate Center of Mass (CoM)\n        com = self._compute_com(robot_state)\n\n        # Validate ZMP within support polygon\n        support_polygon = self._compute_support_polygon(robot_state, environment_state)\n        zmp_in_support = self._is_point_in_polygon(zmp[:2], support_polygon)\n\n        # Validate CoM within stability margins\n        com_stable = np.all(np.abs(com[:2] - cop[:2]) < self.config["balance_validation"]["zmp_tracking"]["com_stability"])\n\n        # Calculate errors\n        zmp_error = np.linalg.norm(zmp[:2] - com[:2])\n\n        return {\n            "zmp_in_support": zmp_in_support,\n            "com_stable": com_stable,\n            "zmp_error": zmp_error,\n            "cop": cop,\n            "com": com,\n            "support_polygon": support_polygon\n        }\n\n    def _compute_zmp(self, robot_state):\n        """Compute Zero-Moment Point"""\n        # Simplified ZMP computation\n        # In practice, this would use the full dynamic model\n        com_pos = robot_state["com_position"]\n        com_vel = robot_state["com_velocity"]\n        com_acc = robot_state["com_acceleration"]\n        gravity = 9.81\n\n        # ZMP = CoM - (CoM_z / g) * CoM_ddot_xy\n        zmp_x = com_pos[0] - (com_pos[2] / gravity) * com_acc[0]\n        zmp_y = com_pos[1] - (com_pos[2] / gravity) * com_acc[1]\n\n        return np.array([zmp_x, zmp_y, 0.0])\n\n    def _compute_cop(self, robot_state, env_state):\n        """Compute Center of Pressure from force/torque sensors"""\n        # Get force/torque measurements from foot sensors\n        left_foot_wrench = robot_state.get("left_foot_wrench", np.zeros(6))\n        right_foot_wrench = robot_state.get("right_foot_wrench", np.zeros(6))\n\n        # Calculate CoP from force/torque measurements\n        # CoP = -T \xd7 F / ||F||\xb2 (simplified)\n        total_force = left_foot_wrench[:3] + right_foot_wrench[:3]\n        total_torque = left_foot_wrench[3:] + right_foot_wrench[3:]\n\n        if np.linalg.norm(total_force[:2]) > 1e-6:  # Avoid division by zero\n            cop_x = -total_torque[1] / total_force[2] if abs(total_force[2]) > 1e-6 else 0.0\n            cop_y = total_torque[0] / total_force[2] if abs(total_force[2]) > 1e-6 else 0.0\n        else:\n            cop_x = 0.0\n            cop_y = 0.0\n\n        return np.array([cop_x, cop_y, 0.0])\n\n    def _compute_com(self, robot_state):\n        """Compute Center of Mass"""\n        # Get CoM from robot state\n        return np.array(robot_state.get("com_position", [0.0, 0.0, 0.0]))\n\n    def _compute_support_polygon(self, robot_state, env_state):\n        """Compute support polygon based on contact points"""\n        # Determine contact points based on foot positions and ground contact\n        left_foot_pos = robot_state.get("left_foot_position", [0.0, 0.0, 0.0])\n        right_foot_pos = robot_state.get("right_foot_position", [0.0, 0.0, 0.0])\n\n        # Get foot geometry\n        foot_size = [0.15, 0.08]  # Length, width\n\n        # Calculate support polygon vertices\n        support_vertices = []\n\n        # Add vertices for left foot if in contact\n        if self._is_foot_in_contact(robot_state, "left"):\n            left_foot_vertices = self._get_foot_polygon(left_foot_pos, foot_size)\n            support_vertices.extend(left_foot_vertices)\n\n        # Add vertices for right foot if in contact\n        if self._is_foot_in_contact(robot_state, "right"):\n            right_foot_vertices = self._get_foot_polygon(right_foot_pos, foot_size)\n            support_vertices.extend(right_foot_vertices)\n\n        return np.array(support_vertices)\n\n    def _is_foot_in_contact(self, robot_state, foot_name):\n        """Check if specified foot is in contact with ground"""\n        contact_force_threshold = 10.0  # Newtons\n\n        if foot_name == "left":\n            wrench = robot_state.get("left_foot_wrench", np.zeros(6))\n        else:\n            wrench = robot_state.get("right_foot_wrench", np.zeros(6))\n\n        return abs(wrench[2]) > contact_force_threshold\n\n    def _get_foot_polygon(self, foot_pos, foot_size):\n        """Get polygon vertices for foot"""\n        length, width = foot_size\n        half_length, half_width = length / 2.0, width / 2.0\n\n        vertices = [\n            [foot_pos[0] + half_length, foot_pos[1] + half_width],\n            [foot_pos[0] + half_length, foot_pos[1] - half_width],\n            [foot_pos[0] - half_length, foot_pos[1] - half_width],\n            [foot_pos[0] - half_length, foot_pos[1] + half_width]\n        ]\n\n        return vertices\n\n    def _is_point_in_polygon(self, point, polygon):\n        """Check if point is inside polygon using ray casting algorithm"""\n        x, y = point\n        n = len(polygon)\n        inside = False\n\n        p1x, p1y = polygon[0]\n        for i in range(1, n + 1):\n            p2x, p2y = polygon[i % n]\n            if y > min(p1y, p2y):\n                if y <= max(p1y, p2y):\n                    if x <= max(p1x, p2x):\n                        if p1y != p2y:\n                            xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x\n                        if p1x == p2x or x <= xinters:\n                            inside = not inside\n            p1x, p1y = p2x, p2y\n\n        return inside\n\n    def validate_locomotion_dynamics(self, trajectory_data):\n        """Validate locomotion dynamics against real-world benchmarks"""\n        validation_results = {\n            "walking_stability": self._validate_walking_stability(trajectory_data),\n            "turning_accuracy": self._validate_turning_accuracy(trajectory_data),\n            "terrain_adaptation": self._validate_terrain_adaptation(trajectory_data)\n        }\n\n        return validation_results\n\n    def _validate_walking_stability(self, trajectory_data):\n        """Validate walking stability metrics"""\n        # Extract pose data\n        poses = trajectory_data["poses"]\n        timestamps = trajectory_data["timestamps"]\n\n        # Calculate stability metrics\n        roll_angles = []\n        pitch_angles = []\n        walking_speeds = []\n\n        for i in range(len(poses)):\n            # Extract orientation\n            orientation = poses[i][3:]  # [qx, qy, qz, qw]\n            euler = self._quaternion_to_euler(orientation)\n\n            roll_angles.append(euler[0])\n            pitch_angles.append(euler[1])\n\n            # Calculate walking speed if we have consecutive poses\n            if i > 0:\n                pos_diff = np.array(poses[i][:3]) - np.array(poses[i-1][:3])\n                time_diff = timestamps[i] - timestamps[i-1]\n                if time_diff > 0:\n                    speed = np.linalg.norm(pos_diff[:2]) / time_diff\n                    walking_speeds.append(speed)\n\n        # Calculate statistics\n        max_roll = max(abs(a) for a in roll_angles)\n        max_pitch = max(abs(a) for a in pitch_angles)\n        avg_speed = sum(walking_speeds) / len(walking_speeds) if walking_speeds else 0.0\n\n        # Validate against thresholds\n        stable_roll = max_roll < self.config["locomotion_validation"]["walking_stability"]["max_roll_angle"]\n        stable_pitch = max_pitch < self.config["locomotion_validation"]["walking_stability"]["max_pitch_angle"]\n\n        return {\n            "stable_roll": stable_roll,\n            "stable_pitch": stable_pitch,\n            "max_roll_angle": max_roll,\n            "max_pitch_angle": max_pitch,\n            "avg_walking_speed": avg_speed,\n            "stability_score": (stable_roll and stable_pitch)\n        }\n\n    def _quaternion_to_euler(self, quat):\n        """Convert quaternion to Euler angles (roll, pitch, yaw)"""\n        w, x, y, z = quat\n\n        # Roll (x-axis rotation)\n        sinr_cosp = 2 * (w * x + y * z)\n        cosr_cosp = 1 - 2 * (x * x + y * y)\n        roll = np.arctan2(sinr_cosp, cosr_cosp)\n\n        # Pitch (y-axis rotation)\n        sinp = 2 * (w * y - z * x)\n        if abs(sinp) >= 1:\n            pitch = np.sign(sinp) * np.pi / 2  # Use 90 degrees if out of range\n        else:\n            pitch = np.arcsin(sinp)\n\n        # Yaw (z-axis rotation)\n        siny_cosp = 2 * (w * z + x * y)\n        cosy_cosp = 1 - 2 * (y * y + z * z)\n        yaw = np.arctan2(siny_cosp, cosy_cosp)\n\n        return np.array([roll, pitch, yaw])\n'})}),"\n",(0,i.jsx)(e.h2,{id:"102-performance-optimization-techniques",children:"10.2 Performance Optimization Techniques"}),"\n",(0,i.jsx)(e.h3,{id:"1021-simulation-performance-profiling",children:"10.2.1 Simulation Performance Profiling"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Performance optimization for Isaac Sim humanoid simulation\nperformance_config = {\n    "simulation_optimization": {\n        "physics_optimization": {\n            "solver_type": "TGS",                    # TGS or PGS solver\n            "position_iterations": 8,                # Position solver iterations\n            "velocity_iterations": 4,                # Velocity solver iterations\n            "max_substeps": 16,                      # Maximum substeps per frame\n            "adaptivity_threshold": 0.1,             # Substep adaptivity threshold\n            "threading": {\n                "worker_threads": 8,                 # Number of physics worker threads\n                "parallel_solver": True,             # Enable parallel solving\n                "task_graph_optimization": True      # Optimize task graph execution\n            }\n        },\n        "rendering_optimization": {\n            "resolution_scaling": 0.8,               # Render at reduced resolution\n            "level_of_detail": {\n                "enable_lod": True,                  # Enable level of detail\n                "distance_thresholds": [5.0, 10.0, 20.0],  # LOD distance thresholds (m)\n                "detail_reduction": [0.5, 0.25, 0.1]        # Detail reduction factors\n            },\n            "culling": {\n                "frustum_culling": True,             # Enable frustum culling\n                "occlusion_culling": True,           # Enable occlusion culling\n                "distance_culling": True,            # Enable distance culling\n                "cull_distance": 50.0                # Cull distance (m)\n            },\n            "shading": {\n                "texture_resolution": "medium",      # Texture resolution level\n                "shadow_quality": "low",             # Shadow quality\n                "reflection_quality": "off",         # Reflection quality\n                "post_processing": "minimal"         # Post-processing level\n            }\n        },\n        "memory_optimization": {\n            "gpu_cache_size": 2048,                  # GPU cache size (MB)\n            "usd_stage_cache": 128,                  # USD stage cache size\n            "texture_cache": 1024,                   # Texture cache size (MB)\n            "geometry_cache": 512,                   # Geometry cache size (MB)\n            "animation_cache": 256                   # Animation cache size (MB)\n        }\n    },\n    "training_specific_optimizations": {\n        "multi_env_training": {\n            "num_environments": 4096,                # Number of parallel environments\n            "env_spacing": 2.0,                      # Distance between environments\n            "shared_assets": True,                   # Share static assets between envs\n            "instance_rendering": True,              # Use instanced rendering\n            "batch_rendering": True                  # Enable batch rendering\n        },\n        "mixed_precision_training": {\n            "use_fp16": True,                        # Use half precision\n            "tensor_cores": True,                    # Enable tensor cores\n            "gradient_scaling": True                 # Automatic gradient scaling\n        },\n        "distributed_training": {\n            "num_processes": 8,                      # Number of training processes\n            "communication_backend": "nccl",         # Communication backend\n            "gradient_compression": True             # Compress gradients\n        }\n    }\n}\n\n# Implementation of performance profiler\nclass PerformanceProfiler:\n    """Profile and optimize Isaac Sim performance"""\n\n    def __init__(self, config):\n        self.config = config\n        self.metrics_history = {\n            "fps": [],\n            "physics_time": [],\n            "rendering_time": [],\n            "memory_usage": [],\n            "gpu_utilization": []\n        }\n\n    def start_profiling(self):\n        """Start performance profiling"""\n        self.profiling_start_time = time.time()\n        self.frame_count = 0\n        self.physics_times = []\n        self.rendering_times = []\n\n        print("Performance profiling started...")\n\n    def record_frame_metrics(self, physics_time, rendering_time):\n        """Record metrics for a single simulation frame"""\n        self.frame_count += 1\n\n        # Record timing metrics\n        self.physics_times.append(physics_time)\n        self.rendering_times.append(rendering_time)\n\n        # Calculate FPS\n        elapsed_time = time.time() - self.profiling_start_time\n        fps = self.frame_count / elapsed_time if elapsed_time > 0 else 0\n\n        # Get memory and GPU usage (simplified)\n        memory_usage = psutil.virtual_memory().percent\n        gpu_utilization = self._get_gpu_utilization()\n\n        # Store metrics\n        self.metrics_history["fps"].append(fps)\n        self.metrics_history["physics_time"].append(physics_time)\n        self.metrics_history["rendering_time"].append(rendering_time)\n        self.metrics_history["memory_usage"].append(memory_usage)\n        self.metrics_history["gpu_utilization"].append(gpu_utilization)\n\n    def _get_gpu_utilization(self):\n        """Get GPU utilization (simplified implementation)"""\n        # In a real implementation, this would use pynvml or similar\n        try:\n            import pynvml\n            pynvml.nvmlInit()\n            handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n            util = pynvml.nvmlDeviceGetUtilizationRates(handle)\n            return util.gpu\n        except:\n            return 0  # Return 0 if unable to get GPU utilization\n\n    def get_performance_report(self):\n        """Generate performance report"""\n        if not self.metrics_history["fps"]:\n            return "No performance data collected"\n\n        # Calculate statistics\n        avg_fps = sum(self.metrics_history["fps"]) / len(self.metrics_history["fps"])\n        avg_physics_time = sum(self.metrics_history["physics_time"]) / len(self.metrics_history["physics_time"])\n        avg_rendering_time = sum(self.metrics_history["rendering_time"]) / len(self.metrics_history["rendering_time"])\n        avg_memory_usage = sum(self.metrics_history["memory_usage"]) / len(self.metrics_history["memory_usage"])\n        avg_gpu_utilization = sum(self.metrics_history["gpu_utilization"]) / len(self.metrics_history["gpu_utilization"])\n\n        # Calculate frame time breakdown\n        total_frame_time = avg_physics_time + avg_rendering_time\n        physics_percentage = (avg_physics_time / total_frame_time) * 100 if total_frame_time > 0 else 0\n        rendering_percentage = (avg_rendering_time / total_frame_time) * 100 if total_frame_time > 0 else 0\n\n        report = f"""\nPerformance Report\n=================\n\nOverall Performance:\n- Average FPS: {avg_fps:.2f}\n- Target FPS: 60.0\n- Performance Score: {(avg_fps / 60.0) * 100:.1f}%\n\nFrame Time Breakdown:\n- Physics: {avg_physics_time*1000:.2f}ms ({physics_percentage:.1f}%)\n- Rendering: {avg_rendering_time*1000:.2f}ms ({rendering_percentage:.1f}%)\n- Total: {total_frame_time*1000:.2f}ms\n\nResource Utilization:\n- Memory Usage: {avg_memory_usage:.1f}%\n- GPU Utilization: {avg_gpu_utilization:.1f}%\n\nRecommendations:\n"""\n\n        # Add recommendations based on performance data\n        if avg_fps < 30:\n            report += "- CRITICAL: Performance is significantly below target. Consider reducing scene complexity.\\n"\n        elif avg_fps < 50:\n            report += "- WARNING: Performance below target. Consider optimizing rendering settings.\\n"\n\n        if avg_memory_usage > 80:\n            report += "- High memory usage detected. Consider reducing asset resolution or using LOD.\\n"\n\n        if avg_gpu_utilization > 90:\n            report += "- High GPU utilization. Consider reducing rendering quality.\\n"\n\n        if physics_percentage > 60:\n            report += "- Physics is consuming majority of frame time. Consider simplifying collision geometry.\\n"\n\n        return report\n\n    def optimize_for_training(self):\n        """Apply optimizations for training scenarios"""\n        print("Applying training-specific optimizations...")\n\n        # Disable rendering for training\n        self._disable_rendering()\n\n        # Reduce physics accuracy for faster simulation\n        self._reduce_physics_accuracy()\n\n        # Enable multi-environment training settings\n        self._enable_multi_env_training()\n\n        print("Training optimizations applied.")\n\n    def optimize_for_visualization(self):\n        """Apply optimizations for visualization scenarios"""\n        print("Applying visualization-specific optimizations...")\n\n        # Enable high-quality rendering\n        self._enable_high_quality_rendering()\n\n        # Increase physics accuracy\n        self._increase_physics_accuracy()\n\n        # Disable multi-env optimizations that sacrifice quality\n        self._disable_multi_env_training()\n\n        print("Visualization optimizations applied.")\n\n    def _disable_rendering(self):\n        """Disable rendering for training"""\n        # This would interact with Isaac Sim\'s rendering system\n        print("  - Disabled rendering pipeline")\n\n    def _reduce_physics_accuracy(self):\n        """Reduce physics accuracy for speed"""\n        print("  - Reduced physics solver iterations")\n        print("  - Reduced collision mesh complexity")\n\n    def _enable_multi_env_training(self):\n        """Enable multi-environment training optimizations"""\n        print("  - Enabled instance rendering")\n        print("  - Shared static assets between environments")\n        print("  - Enabled batch processing")\n\n    def _enable_high_quality_rendering(self):\n        """Enable high-quality rendering"""\n        print("  - Enabled high-resolution textures")\n        print("  - Enabled realistic lighting and shadows")\n        print("  - Enabled post-processing effects")\n\n    def _increase_physics_accuracy(self):\n        """Increase physics accuracy"""\n        print("  - Increased physics solver iterations")\n        print("  - Enabled continuous collision detection")\n        print("  - Increased collision mesh resolution")\n\n    def _disable_multi_env_training(self):\n        """Disable multi-environment training optimizations"""\n        print("  - Disabled instance rendering (for quality)")\n        print("  - Disabled shared assets (for quality)")\n'})})]})}function p(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(_,{...n})}):_(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>r,x:()=>s});var i=t(6540);const o={},a=i.createContext(o);function r(n){const e=i.useContext(a);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:r(n.components),i.createElement(a.Provider,{value:e},n.children)}}}]);