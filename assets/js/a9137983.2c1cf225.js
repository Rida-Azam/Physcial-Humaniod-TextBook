"use strict";(self.webpackChunkphysical_ai_textbook=self.webpackChunkphysical_ai_textbook||[]).push([[294],{8180:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var t=i(4848),a=i(8453);const r={id:"chapter8",sidebar_position:3,title:"Building High-Fidelity Environments & Sensor Simulation"},o="Chapter 8: Building High-Fidelity Environments & Sensor Simulation",s={id:"module2/chapter8",title:"Building High-Fidelity Environments & Sensor Simulation",description:"Learning Objectives",source:"@site/docs/module2/chapter8.mdx",sourceDirName:"module2",slug:"/module2/chapter8",permalink:"/physical-ai-textbook/docs/module2/chapter8",draft:!1,unlisted:!1,editUrl:"https://github.com/your-github-username/physical-ai-textbook/tree/main/docs/module2/chapter8.mdx",tags:[],version:"current",sidebarPosition:3,frontMatter:{id:"chapter8",sidebar_position:3,title:"Building High-Fidelity Environments & Sensor Simulation"},sidebar:"tutorialSidebar",previous:{title:"NVIDIA Isaac Sim \u2013 The New Standard for Humanoid Training",permalink:"/physical-ai-textbook/docs/module2/chapter7"},next:{title:"Isaac Sim Integration \u2013 Physics, Rendering & Sensor Simulation",permalink:"/physical-ai-textbook/docs/module2/chapter9"}},l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"8.1 Introduction to High-Fidelity Environments",id:"81-introduction-to-high-fidelity-environments",level:2},{value:"8.1.1 Importance of Environmental Fidelity",id:"811-importance-of-environmental-fidelity",level:3},{value:"8.1.2 Fidelity vs. Performance Trade-offs",id:"812-fidelity-vs-performance-trade-offs",level:3},{value:"8.2 Environment Design Principles",id:"82-environment-design-principles",level:2},{value:"8.2.1 Realistic Scene Construction",id:"821-realistic-scene-construction",level:3},{value:"8.2.2 Modular Environment Design",id:"822-modular-environment-design",level:3},{value:"8.2.3 Dynamic Environment Elements",id:"823-dynamic-environment-elements",level:3},{value:"8.3 Sensor Simulation Fundamentals",id:"83-sensor-simulation-fundamentals",level:2},{value:"8.3.1 Camera Simulation",id:"831-camera-simulation",level:3},{value:"8.3.2 IMU Simulation",id:"832-imu-simulation",level:3},{value:"8.3.3 Force/Torque Sensor Simulation",id:"833-forcetorque-sensor-simulation",level:3},{value:"8.4 Domain Randomization Techniques",id:"84-domain-randomization-techniques",level:2},{value:"8.4.1 Visual Domain Randomization",id:"841-visual-domain-randomization",level:3},{value:"8.4.2 Physical Domain Randomization",id:"842-physical-domain-randomization",level:3},{value:"8.5 Creating Diverse Environments",id:"85-creating-diverse-environments",level:2},{value:"8.5.1 Indoor Environment Variants",id:"851-indoor-environment-variants",level:3},{value:"8.5.2 Outdoor Environment Variants",id:"852-outdoor-environment-variants",level:3},{value:"8.6 Environment Validation and Quality Assurance",id:"86-environment-validation-and-quality-assurance",level:2},{value:"8.6.1 Validation Metrics",id:"861-validation-metrics",level:3},{value:"8.6.2 Automated Testing Framework",id:"862-automated-testing-framework",level:3},{value:"8.7 Performance Optimization",id:"87-performance-optimization",level:2},{value:"8.7.1 Rendering Optimization",id:"871-rendering-optimization",level:3},{value:"8.7.2 Physics Optimization",id:"872-physics-optimization",level:3},{value:"8.8 Integration with Isaac Sim",id:"88-integration-with-isaac-sim",level:2},{value:"8.8.1 Environment Loading and Management",id:"881-environment-loading-and-management",level:3},{value:"8.8.2 Sensor Integration",id:"882-sensor-integration",level:3},{value:"8.9 Summary",id:"89-summary",level:2},{value:"Exercises",id:"exercises",level:2},{value:"References",id:"references",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h1,{id:"chapter-8-building-high-fidelity-environments--sensor-simulation",children:"Chapter 8: Building High-Fidelity Environments & Sensor Simulation"}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(e.p,{children:"By the end of this chapter, students will be able to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Design and create realistic simulation environments for humanoid robots"}),"\n",(0,t.jsx)(e.li,{children:"Implement high-fidelity sensor simulation including cameras, IMUs, and force sensors"}),"\n",(0,t.jsx)(e.li,{children:"Apply domain randomization techniques to improve sim-to-real transfer"}),"\n",(0,t.jsx)(e.li,{children:"Create diverse environments that match real-world deployment scenarios"}),"\n",(0,t.jsx)(e.li,{children:"Validate simulation environments against real-world conditions"}),"\n",(0,t.jsx)(e.li,{children:"Optimize simulation performance while maintaining environmental fidelity"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"81-introduction-to-high-fidelity-environments",children:"8.1 Introduction to High-Fidelity Environments"}),"\n",(0,t.jsx)(e.p,{children:"Creating high-fidelity simulation environments is crucial for humanoid robotics, as these robots must operate in complex, unstructured human environments. The simulation environment must accurately represent:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Visual Appearance"}),": Photorealistic rendering for vision-based perception"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Physical Properties"}),": Accurate physics for interaction modeling"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Sensor Characteristics"}),": Realistic sensor noise and limitations"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Environmental Dynamics"}),": Moving objects, changing conditions, etc."]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"811-importance-of-environmental-fidelity",children:"8.1.1 Importance of Environmental Fidelity"}),"\n",(0,t.jsx)(e.p,{children:"Environmental fidelity directly impacts the success of sim-to-real transfer:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Visual Fidelity"}),": Affects vision-based perception and learning"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Physical Fidelity"}),": Influences locomotion and manipulation policies"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Sensor Fidelity"}),": Impacts state estimation and control accuracy"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Temporal Fidelity"}),": Affects real-time performance and reaction times"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"812-fidelity-vs-performance-trade-offs",children:"8.1.2 Fidelity vs. Performance Trade-offs"}),"\n",(0,t.jsx)(e.p,{children:"When designing simulation environments, consider:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Computational Cost"}),": Higher fidelity often means higher computational requirements"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Training Efficiency"}),": Balance between realism and training speed"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Transfer Quality"}),": Ensure fidelity improvements actually help real-world performance"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Development Time"}),": More complex environments require more development effort"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"82-environment-design-principles",children:"8.2 Environment Design Principles"}),"\n",(0,t.jsx)(e.h3,{id:"821-realistic-scene-construction",children:"8.2.1 Realistic Scene Construction"}),"\n",(0,t.jsx)(e.p,{children:"Creating realistic environments requires attention to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Geometric Accuracy"}),": Precise representation of real-world spaces"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Material Properties"}),": Accurate appearance and physics properties"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Lighting Conditions"}),": Realistic lighting for vision systems"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Dynamic Elements"}),": Moving objects and changing conditions"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"822-modular-environment-design",children:"8.2.2 Modular Environment Design"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Example modular environment design for Isaac Sim\nimport omni\nfrom pxr import UsdGeom, Sdf\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.utils.prims import get_prim_at_path\nimport numpy as np\n\nclass ModularEnvironmentBuilder:\n    """Modular system for building simulation environments"""\n\n    def __init__(self):\n        self.environment_modules = {\n            "floors": {\n                "wood": "/Isaac/Environments/Simple_Rooms/wood_plane.usd",\n                "tile": "/Isaac/Environments/Simple_Rooms/tile_plane.usd",\n                "carpet": "/Isaac/Environments/Simple_Rooms/carpet_plane.usd",\n                "concrete": "/Isacs/Environments/Simple_Rooms/concrete_plane.usd"\n            },\n            "furniture": {\n                "chair": "/Isaac/Props/Small_Table/small_table.usd",\n                "table": "/Isaac/Props/Chair/chair.usd",\n                "shelf": "/Isaac/Props/Shelf/shelf.usd",\n                "cabinet": "/Isaac/Props/Cabinet/cabinet.usd"\n            },\n            "obstacles": {\n                "box": "/Isaac/Props/Box/small.urdf",\n                "cylinder": "/Isaac/Props/Cylinder/cylinder.usdf",\n                "cone": "/Isaac/Props/Cone/cone.usd"\n            }\n        }\n\n    def build_room_environment(self, room_type="office", size=(5.0, 5.0)):\n        """Build a room-based environment"""\n        # Create room boundary\n        self._create_room_boundary(size)\n\n        # Add floor based on room type\n        floor_type = self._select_floor_type(room_type)\n        self._add_floor(floor_type, size)\n\n        # Add furniture based on room type\n        furniture_config = self._get_furniture_config(room_type)\n        self._add_furniture(furniture_config, size)\n\n        # Add lighting\n        self._add_lighting(room_type)\n\n    def _create_room_boundary(self, size):\n        """Create walls for the room"""\n        # Create walls using plane prims\n        wall_thickness = 0.1\n        height = 3.0\n\n        # Wall positions\n        walls = [\n            {"name": "wall_front", "size": (size[0], wall_thickness, height), "pos": (0, -size[1]/2, height/2)},\n            {"name": "wall_back", "size": (size[0], wall_thickness, height), "pos": (0, size[1]/2, height/2)},\n            {"name": "wall_left", "size": (wall_thickness, size[1], height), "pos": (-size[0]/2, 0, height/2)},\n            {"name": "wall_right", "size": (wall_thickness, size[1], height), "pos": (size[0]/2, 0, height/2)}\n        ]\n\n        for wall in walls:\n            # Add wall to stage\n            wall_path = f"/World/{wall[\'name\']}"\n            wall_geom = UsdGeom.Cube.Define(self.stage, wall_path)\n            wall_geom.CreateSizeAttr(wall[\'size\'])\n            wall_geom.AddTranslateOp().Set(wall[\'pos\'])\n\n    def _select_floor_type(self, room_type):\n        """Select appropriate floor type for room"""\n        floor_mapping = {\n            "office": "tile",\n            "living_room": "wood",\n            "kitchen": "tile",\n            "bedroom": "carpet",\n            "industrial": "concrete"\n        }\n        return floor_mapping.get(room_type, "tile")\n\n    def _get_furniture_config(self, room_type):\n        """Get furniture configuration for room type"""\n        furniture_configs = {\n            "office": [\n                {"type": "chair", "position": (-1.0, 0.0, 0.0), "rotation": (0, 0, 0, 1)},\n                {"type": "table", "position": (-1.0, 0.0, 0.0), "rotation": (0, 0, 0, 1)},\n                {"type": "shelf", "position": (1.5, 1.0, 0.0), "rotation": (0, 0, 0, 1)}\n            ],\n            "living_room": [\n                {"type": "chair", "position": (-1.0, -1.0, 0.0), "rotation": (0, 0, 0, 1)},\n                {"type": "chair", "position": (-1.0, 1.0, 0.0), "rotation": (0, 0, 0, 1)},\n                {"type": "table", "position": (0.0, 0.0, 0.0), "rotation": (0, 0, 0, 1)}\n            ],\n            "kitchen": [\n                {"type": "cabinet", "position": (0.0, -2.0, 0.0), "rotation": (0, 0, 0, 1)},\n                {"type": "table", "position": (0.0, 0.0, 0.0), "rotation": (0, 0, 0, 1)}\n            ]\n        }\n        return furniture_configs.get(room_type, [])\n\n    def _add_furniture(self, furniture_config, room_size):\n        """Add furniture to environment"""\n        for i, furniture in enumerate(furniture_config):\n            # Check bounds\n            pos = furniture[\'position\']\n            if (abs(pos[0]) > room_size[0]/2 - 0.5 or\n                abs(pos[1]) > room_size[1]/2 - 0.5):\n                print(f"Furniture position {pos} out of bounds for room size {room_size}")\n                continue\n\n            # Add furniture to stage\n            furniture_path = f"/World/Furniture/furniture_{i}"\n            add_reference_to_stage(\n                usd_path=self.environment_modules["furniture"][furniture["type"]],\n                prim_path=furniture_path\n            )\n\n            # Set position and rotation\n            prim = get_prim_at_path(furniture_path)\n            prim.GetAttribute("xformOp:translate").Set(pos)\n            prim.GetAttribute("xformOp:orient").Set(furniture["rotation"])\n\n    def _add_lighting(self, room_type):\n        """Add appropriate lighting for room type"""\n        # Add overhead lights\n        for i in range(2):\n            light_path = f"/World/Light/light_{i}"\n            light = UsdGeom.Sphere.Define(self.stage, light_path)\n            light.CreateRadiusAttr(0.1)\n\n            # Position lights\n            x_pos = -1.0 + i * 2.0\n            light.AddTranslateOp().Set((x_pos, 0.0, 2.5))\n\n            # Add light emission (in a real implementation)\n            # light.GetAttribute("emissiveColor").Set((1.0, 1.0, 1.0))\n\n# Example usage\nenv_builder = ModularEnvironmentBuilder()\nenv_builder.build_room_environment("office", (6.0, 4.0))\n'})}),"\n",(0,t.jsx)(e.h3,{id:"823-dynamic-environment-elements",children:"8.2.3 Dynamic Environment Elements"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Dynamic environment elements for increased realism\nclass DynamicEnvironmentElements:\n    """Add dynamic elements to environments"""\n\n    def __init__(self):\n        self.dynamic_objects = []\n        self.environment_conditions = {\n            "lighting": {\n                "intensity_range": (0.5, 1.5),\n                "temperature_range": (3000, 6500),  # Kelvin\n                "shadow_softness": (0.1, 0.5)\n            },\n            "weather": {\n                "wind_speed_range": (0.0, 5.0),  # m/s\n                "precipitation": False,\n                "fog_density": (0.0, 0.1)\n            },\n            "objects": {\n                "movable_objects": True,\n                "deformable_objects": False,\n                "articulated_objects": True\n            }\n        }\n\n    def add_dynamic_objects(self, object_config):\n        """Add dynamic objects to environment"""\n        # Create objects with realistic dynamics\n        for obj in object_config:\n            if obj["movable"]:\n                self._make_object_movable(obj)\n            if obj["articulated"]:\n                self._add_joints(obj)\n\n    def add_weather_effects(self, weather_config):\n        """Add weather-related effects"""\n        # In Isaac Sim, this would involve:\n        # - Particle systems for precipitation\n        # - Wind forces\n        # - Atmospheric effects\n        pass\n\n    def add_lighting_variations(self, lighting_config):\n        """Add lighting variations"""\n        # Modify light intensities and colors\n        # Add shadows and reflections\n        pass\n'})}),"\n",(0,t.jsx)(e.h2,{id:"83-sensor-simulation-fundamentals",children:"8.3 Sensor Simulation Fundamentals"}),"\n",(0,t.jsx)(e.h3,{id:"831-camera-simulation",children:"8.3.1 Camera Simulation"}),"\n",(0,t.jsx)(e.p,{children:"Realistic camera simulation is crucial for vision-based humanoid systems:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Camera simulation parameters\ncamera_simulation_config = {\n    "rgb_camera": {\n        "resolution": [640, 480],\n        "fov": 60,  # Degrees\n        "near_clip": 0.1,  # Meters\n        "far_clip": 100.0,  # Meters\n        "sensor_tilt": 0.0,  # Radians\n        "mounting_height": 1.5,  # Meters above ground\n        "noise": {\n            "gaussian_std": 0.01,  # Standard deviation of Gaussian noise\n            "poisson_multiplier": 0.001,  # Poisson noise multiplier\n            "dropout_probability": 0.001  # Pixel dropout probability\n        },\n        "distortion": {\n            "k1": -0.1,  # Radial distortion coefficients\n            "k2": 0.02,\n            "p1": 0.0,   # Tangential distortion coefficients\n            "p2": 0.0\n        }\n    },\n    "depth_camera": {\n        "resolution": [640, 480],\n        "fov": 60,\n        "near_clip": 0.1,\n        "far_clip": 10.0,\n        "depth_noise_std": 0.01,  # Meters\n        "invalid_depth_value": 0.0\n    },\n    "lidar": {\n        "type": "ray_based",  # Or "sweep_based"\n        "samples": {\n            "horizontal": 1024,\n            "vertical": 64\n        },\n        "range": {\n            "min": 0.1,  # Meters\n            "max": 25.0  # Meters\n        },\n        "rotation_rates": {\n            "horizontal": 10.0,  # Hz\n            "vertical": 2.0    # Hz\n        },\n        "noise": {\n            "range_std": 0.01,  # Meters\n            "angular_std": 0.001  # Radians\n        }\n    }\n}\n\n# Example camera implementation\ndef create_realistic_camera(stage, camera_path, config):\n    """Create a realistic camera in Isaac Sim"""\n    from omni.isaac.sensor import Camera\n\n    # Create camera\n    camera = Camera(\n        prim_path=camera_path,\n        frequency=config["rgb_camera"]["fov"],\n        resolution=config["rgb_camera"]["resolution"]\n    )\n\n    # Apply noise parameters\n    camera.add_noise_params(\n        gaussian_std=config["rgb_camera"]["noise"]["gaussian_std"],\n        poisson_multiplier=config["rgb_camera"]["noise"]["poisson_multiplier"],\n        dropout_probability=config["rgb_camera"]["noise"]["dropout_probability"]\n    )\n\n    # Apply distortion parameters\n    camera.set_distortion_params(\n        k1=config["rgb_camera"]["distortion"]["k1"],\n        k2=config["rgb_camera"]["distortion"]["k2"],\n        p1=config["rgb_camera"]["distortion"]["p1"],\n        p2=config["rgb_camera"]["distortion"]["p2"]\n    )\n\n    return camera\n'})}),"\n",(0,t.jsx)(e.h3,{id:"832-imu-simulation",children:"8.3.2 IMU Simulation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# IMU simulation parameters\nimu_simulation_config = {\n    "accelerometer": {\n        "range": 16.0,  # g (Earth gravities)\n        "resolution": 1e-6,  # g per LSB\n        "noise_density": 100.0e-6,  # g/sqrt(Hz)\n        "random_walk": 1.0e-6,  # g/s^2/sqrt(Hz)\n        "bias_instability": 5.0e-6,  # g\n        "turn_on_bias_sigma": 20.0e-6  # g\n    },\n    "gyroscope": {\n        "range": 2000.0,  # deg/s\n        "resolution": 0.001,  # deg/s per LSB\n        "noise_density": 0.01,  # deg/s/sqrt(Hz)\n        "random_walk": 0.0038,  # deg/s^2/sqrt(Hz)\n        "bias_instability": 10.0,  # deg/hour/sqrt(Hz)\n        "turn_on_bias_sigma": 0.5  # deg/s\n    },\n    "magnetometer": {\n        "range": 1300.0,  # microTesla\n        "resolution": 0.1,  # microTesla per LSB\n        "noise_density": 100.0,  # nT/sqrt(Hz)\n        "hard_iron_distortion": [0.0, 0.0, 0.0],  # microTesla\n        "soft_iron_matrix": [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]\n    },\n    "sensor_mounting": {\n        "position": [0.0, 0.0, 0.0],  # Relative to body frame\n        "orientation": [0.0, 0.0, 0.0, 1.0],  # Quaternion\n        "alignment_errors": {\n            "position_std": 0.001,  # Meters\n            "angle_std": 0.001  # Radians\n        }\n    }\n}\n\n# Example IMU simulation\ndef create_realistic_imu(stage, imu_path, config):\n    """Create a realistic IMU in Isaac Sim"""\n    from omni.isaac.sensor import IMU\n\n    # Create IMU\n    imu = IMU(\n        prim_path=imu_path,\n        frequency=100  # 100 Hz sampling rate\n    )\n\n    # Apply noise models based on configuration\n    imu.set_noise_params(\n        accel_noise_density=config["accelerometer"]["noise_density"],\n        gyro_noise_density=config["gyroscope"]["noise_density"],\n        accel_random_walk=config["accelerometer"]["random_walk"],\n        gyro_random_walk=config["gyroscope"]["random_walk"],\n        accel_bias_instability=config["accelerometer"]["bias_instability"],\n        gyro_bias_instability=config["gyroscope"]["bias_instability"]\n    )\n\n    return imu\n'})}),"\n",(0,t.jsx)(e.h3,{id:"833-forcetorque-sensor-simulation",children:"8.3.3 Force/Torque Sensor Simulation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Force/Torque sensor simulation\nft_sensor_simulation_config = {\n    "wrench_sensor": {\n        "measurement_range": {\n            "force": [500.0, 500.0, 500.0],  # [Fx, Fy, Fz] in Newtons\n            "torque": [50.0, 50.0, 50.0]    # [Tx, Ty, Tz] in Nm\n        },\n        "resolution": {\n            "force": [0.01, 0.01, 0.01],   # Newtons per LSB\n            "torque": [0.001, 0.001, 0.001] # Nm per LSB\n        },\n        "noise": {\n            "force_std": [0.1, 0.1, 0.1],   # Newtons\n            "torque_std": [0.01, 0.01, 0.01] # Nm\n        },\n        "bandwidth": 1000,  # Hz\n        "temperature_drift": {\n            "force_ppm_per_celsius": 50,  # ppm/\xb0C\n            "torque_ppm_per_celsius": 100  # ppm/\xb0C\n        }\n    },\n    "contact_sensors": {\n        "contact_detection_threshold": 1.0,  # Newtons\n        "contact_normal_accuracy": 0.01,     # Radians\n        "contact_location_accuracy": 0.001,  # Meters\n        "slip_detection": True,\n        "friction_estimation": True\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"84-domain-randomization-techniques",children:"8.4 Domain Randomization Techniques"}),"\n",(0,t.jsx)(e.h3,{id:"841-visual-domain-randomization",children:"8.4.1 Visual Domain Randomization"}),"\n",(0,t.jsx)(e.p,{children:"Visual domain randomization helps improve the robustness of vision-based systems:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Visual domain randomization parameters\nvisual_domain_randomization_config = {\n    "appearance_randomization": {\n        "textures": {\n            "brightness_range": (0.5, 1.5),\n            "contrast_range": (0.8, 1.2),\n            "saturation_range": (0.5, 1.5),\n            "hue_range": (-0.1, 0.1)\n        },\n        "materials": {\n            "roughness_range": (0.1, 0.9),\n            "metallic_range": (0.0, 0.5),\n            "specular_range": (0.1, 1.0)\n        },\n        "lighting": {\n            "intensity_range": (0.3, 2.0),\n            "temperature_range": (3000, 8000),  # Kelvin\n            "direction_deviation": (0.0, 0.5)   # Radians\n        }\n    },\n    "geometric_randomization": {\n        "object_poses": {\n            "translation_std": (0.05, 0.05, 0.02),  # Meters\n            "rotation_std": (0.1, 0.1, 0.1)        # Radians\n        },\n        "object_scales": {\n            "uniform_range": (0.9, 1.1),           # Scale factor\n            "nonuniform_range": (0.95, 1.05)       # For anisotropic scaling\n        }\n    },\n    "sensor_randomization": {\n        "camera_intrinsics": {\n            "focal_length_range": (0.9, 1.1),      # Factor\n            "principal_point_range": (-0.05, 0.05) # Normalized coordinates\n        },\n        "distortion_coefficients": {\n            "k1_range": (-0.5, 0.5),\n            "k2_range": (-0.1, 0.1),\n            "p1_range": (-0.001, 0.001),\n            "p2_range": (-0.001, 0.001)\n        }\n    }\n}\n\n# Implementation of visual domain randomization\nclass VisualDomainRandomizer:\n    """Apply visual domain randomization to Isaac Sim environments"""\n\n    def __init__(self, config):\n        self.config = config\n        self.randomization_schedule = self._create_schedule()\n\n    def _create_schedule(self):\n        """Create schedule for when to randomize parameters"""\n        # Linear schedule: randomize more as training progresses\n        schedule = {\n            "start_percentage": 0.0,    # Start with no randomization\n            "end_percentage": 1.0,      # End with full randomization\n            "schedule_length": 1000000  # Total training steps\n        }\n        return schedule\n\n    def randomize_environment(self, step_count, stage):\n        """Apply randomization to environment"""\n        # Calculate randomization strength based on training progress\n        progress = min(step_count / self.randomization_schedule["schedule_length"], 1.0)\n        strength = self.randomization_schedule["start_percentage"] + \\\n                  progress * (self.randomization_schedule["end_percentage"] -\n                             self.randomization_schedule["start_percentage"])\n\n        # Apply appearance randomization\n        if np.random.random() < strength:\n            self._randomize_appearance(stage)\n\n        # Apply geometric randomization\n        if np.random.random() < strength * 0.5:  # Less frequent\n            self._randomize_geometry(stage)\n\n    def _randomize_appearance(self, stage):\n        """Randomize visual appearance of objects"""\n        # Randomize textures\n        for prim_path in self._get_all_texture_prims(stage):\n            if np.random.random() < 0.8:  # 80% chance to randomize\n                # Apply brightness, contrast, saturation changes\n                brightness = np.random.uniform(*self.config["appearance_randomization"]["textures"]["brightness_range"])\n                contrast = np.random.uniform(*self.config["appearance_randomization"]["textures"]["contrast_range"])\n                saturation = np.random.uniform(*self.config["appearance_randomization"]["textures"]["saturation_range"])\n\n                # Apply changes to material properties\n                self._modify_material_properties(prim_path, brightness, contrast, saturation)\n\n        # Randomize lighting\n        for light_path in self._get_all_lights(stage):\n            intensity_factor = np.random.uniform(*self.config["appearance_randomization"]["lighting"]["intensity_range"])\n            temperature = np.random.uniform(*self.config["appearance_randomization"]["lighting"]["temperature_range"])\n\n            # Apply lighting changes\n            self._modify_light_properties(light_path, intensity_factor, temperature)\n\n    def _randomize_geometry(self, stage):\n        """Randomize geometric properties of objects"""\n        # Randomize object poses\n        for object_path in self._get_moveable_objects(stage):\n            if np.random.random() < 0.3:  # 30% chance to move each object\n                # Add small random translation and rotation\n                trans_change = np.random.normal(\n                    scale=self.config["geometric_randomization"]["object_poses"]["translation_std"]\n                )\n                rot_change = np.random.normal(\n                    scale=self.config["geometric_randomization"]["object_poses"]["rotation_std"]\n                )\n\n                # Apply transformation changes\n                self._apply_pose_change(object_path, trans_change, rot_change)\n\n    def _get_all_texture_prims(self, stage):\n        """Get all prims with texture properties"""\n        # Implementation would traverse the USD stage to find textured objects\n        return []  # Placeholder\n\n    def _get_all_lights(self, stage):\n        """Get all light prims"""\n        # Implementation would find all light sources\n        return []  # Placeholder\n\n    def _get_moveable_objects(self, stage):\n        """Get all moveable objects"""\n        # Implementation would find all moveable objects\n        return []  # Placeholder\n'})}),"\n",(0,t.jsx)(e.h3,{id:"842-physical-domain-randomization",children:"8.4.2 Physical Domain Randomization"}),"\n",(0,t.jsx)(e.p,{children:"Physical domain randomization improves sim-to-real transfer for dynamics:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Physical domain randomization parameters\nphysical_domain_randomization_config = {\n    "dynamics_randomization": {\n        "mass": {\n            "multiplier_range": (0.8, 1.2),      # Mass scaling factor\n            "distribution": "uniform"            # uniform, normal, log_normal\n        },\n        "inertia": {\n            "multiplier_range": (0.8, 1.2),      # Inertia scaling factor\n            "distribution": "uniform"\n        },\n        "friction": {\n            "static_range": (0.3, 1.0),          # Static friction range\n            "dynamic_range": (0.2, 0.8),         # Dynamic friction range\n            "distribution": "uniform"\n        },\n        "restitution": {\n            "range": (0.0, 0.3),                 # Coefficient of restitution\n            "distribution": "uniform"\n        }\n    },\n    "actuator_randomization": {\n        "gear_ratios": {\n            "multiplier_range": (0.95, 1.05),    # Gear ratio scaling\n            "distribution": "normal"\n        },\n        "torque_limits": {\n            "multiplier_range": (0.9, 1.0),      # Torque limit scaling\n            "distribution": "uniform"\n        },\n        "velocity_limits": {\n            "multiplier_range": (0.9, 1.1),      # Velocity limit scaling\n            "distribution": "uniform"\n        },\n        "delay": {\n            "range_ms": (1.0, 10.0),             # Command delay in ms\n            "distribution": "uniform"\n        },\n        "noise": {\n            "torque_std_range": (0.001, 0.01),   # Torque noise standard deviation\n            "position_std_range": (0.0001, 0.001) # Position noise standard deviation\n        }\n    },\n    "environment_randomization": {\n        "gravity": {\n            "range": (9.7, 9.9),                 # Gravity magnitude in m/s^2\n            "direction_deviation": (0.0, 0.01)   # Deviation from z-axis in radians\n        },\n        "ground_properties": {\n            "slope_range": (-0.1, 0.1),          # Ground slope in radians\n            "roughness_range": (0.0, 0.01),      # Ground roughness in meters\n            "compliance_range": (1e-6, 1e-4)     # Ground compliance\n        }\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"85-creating-diverse-environments",children:"8.5 Creating Diverse Environments"}),"\n",(0,t.jsx)(e.h3,{id:"851-indoor-environment-variants",children:"8.5.1 Indoor Environment Variants"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Configuration for different indoor environments\nindoor_environment_configs = {\n    "home_environment": {\n        "layout": {\n            "rooms": ["living_room", "kitchen", "bedroom", "bathroom"],\n            "corridors": True,\n            "doorways": True\n        },\n        "furniture": {\n            "common_items": ["chair", "table", "couch", "bed", "dresser"],\n            "density": 0.3,  # 30% of available space occupied\n            "variability": 0.7  # High variability in arrangement\n        },\n        "lighting": {\n            "sources": ["overhead", "lamp", "window"],\n            "intensity_range": (50, 200),  # Lumens\n            "color_temperature_range": (2700, 6500)  # Kelvin\n        },\n        "flooring": {\n            "types": ["wood", "carpet", "tile"],\n            "textures": ["smooth", "textured", "patterned"]\n        },\n        "obstacles": {\n            "static": ["plant", "decorative_item"],\n            "dynamic": ["pet", "child", "vacuum_robot"],\n            "frequency": 0.2  # 20% chance of dynamic obstacles\n        }\n    },\n    "office_environment": {\n        "layout": {\n            "rooms": ["cubicles", "meeting_rooms", "hallways", "break_area"],\n            "open_spaces": True,\n            "partitions": True\n        },\n        "furniture": {\n            "common_items": ["desk", "chair", "cabinet", "plant"],\n            "density": 0.4,\n            "variability": 0.5\n        },\n        "lighting": {\n            "sources": ["fluorescent", "LED", "window"],\n            "intensity_range": (200, 500),\n            "color_temperature_range": (4000, 5000)\n        },\n        "flooring": {\n            "types": ["carpet", "tile", "laminate"],\n            "textures": ["smooth", "anti-fatigue"]\n        },\n        "obstacles": {\n            "static": ["printer", "coffee_station"],\n            "dynamic": ["colleagues", "delivery_robot"],\n            "frequency": 0.3\n        }\n    },\n    "industrial_environment": {\n        "layout": {\n            "areas": ["work_floor", "storage", "assembly", "inspection"],\n            "high_clearance": True,\n            "equipment_zones": True\n        },\n        "furniture": {\n            "common_items": ["workbench", "tool_cabinet", "machine", "pallet"],\n            "density": 0.6,\n            "variability": 0.3\n        },\n        "lighting": {\n            "sources": ["industrial_LED", "overhead_crane_lights"],\n            "intensity_range": (300, 1000),\n            "color_temperature_range": (5000, 6500)\n        },\n        "flooring": {\n            "types": ["concrete", "epoxy", "metal_grating"],\n            "textures": ["smooth", "grippy", "chemical_resistant"]\n        },\n        "obstacles": {\n            "static": ["machinery", "storage_racks", "conveyor"],\n            "dynamic": ["forklift", "workers", "automated_guided_vehicle"],\n            "frequency": 0.5\n        }\n    }\n}\n\n# Implementation for environment creation\nclass EnvironmentCreator:\n    """Create diverse indoor environments"""\n\n    def __init__(self, config):\n        self.config = config\n\n    def create_environment_variant(self, env_type, seed=None):\n        """Create a variant of the specified environment type"""\n        if seed:\n            np.random.seed(seed)\n\n        # Get configuration for environment type\n        env_config = self.config.get(env_type)\n        if not env_config:\n            raise ValueError(f"Unknown environment type: {env_type}")\n\n        # Create base layout\n        stage = self._create_base_layout(env_config["layout"])\n\n        # Add furniture\n        self._add_furniture(stage, env_config["furniture"])\n\n        # Add lighting\n        self._add_lighting(stage, env_config["lighting"])\n\n        # Add flooring\n        self._add_flooring(stage, env_config["flooring"])\n\n        # Add obstacles\n        self._add_obstacles(stage, env_config["obstacles"])\n\n        return stage\n\n    def _create_base_layout(self, layout_config):\n        """Create the base layout of the environment"""\n        # Implementation would create rooms, corridors, etc.\n        stage = omni.usd.get_context().get_stage()\n        return stage\n\n    def _add_furniture(self, stage, furniture_config):\n        """Add furniture to the environment"""\n        # Place furniture according to density and variability\n        pass\n\n    def _add_lighting(self, stage, lighting_config):\n        """Add lighting to the environment"""\n        # Add lights according to configuration\n        pass\n\n    def _add_flooring(self, stage, flooring_config):\n        """Add flooring to the environment"""\n        # Add appropriate floor materials\n        pass\n\n    def _add_obstacles(self, stage, obstacles_config):\n        """Add obstacles to the environment"""\n        # Add static and dynamic obstacles\n        pass\n'})}),"\n",(0,t.jsx)(e.h3,{id:"852-outdoor-environment-variants",children:"8.5.2 Outdoor Environment Variants"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Configuration for outdoor environments\noutdoor_environment_configs = {\n    "urban_environment": {\n        "terrain": {\n            "types": ["sidewalk", "road", "grass", "gravel"],\n            "slope_range": (-0.1, 0.1),\n            "roughness_range": (0.0, 0.05)\n        },\n        "obstacles": {\n            "static": ["lamppost", "bench", "trash_can", "bicycle"],\n            "dynamic": ["pedestrians", "vehicles", "dogs"],\n            "density": 0.1  # Obstacles per square meter\n        },\n        "weather": {\n            "conditions": ["clear", "cloudy", "rainy", "snowy"],\n            "probability": {"clear": 0.6, "cloudy": 0.3, "rainy": 0.08, "snowy": 0.02}\n        },\n        "lighting": {\n            "natural_light": True,\n            "artificial_light": ["street_lamps", "building_lights"],\n            "day_night_cycle": True\n        }\n    },\n    "natural_environment": {\n        "terrain": {\n            "types": ["grass", "dirt", "rock", "sand", "water_edge"],\n            "slope_range": (-0.3, 0.3),\n            "roughness_range": (0.0, 0.2)\n        },\n        "obstacles": {\n            "static": ["tree", "bush", "rock", "stream"],\n            "dynamic": ["animals", "falling_branches"],\n            "density": 0.05\n        },\n        "weather": {\n            "conditions": ["sunny", "partly_cloudy", "rainy", "windy"],\n            "probability": {"sunny": 0.5, "partly_cloudy": 0.3, "rainy": 0.15, "windy": 0.05}\n        },\n        "lighting": {\n            "natural_light": True,\n            "artificial_light": False,\n            "day_night_cycle": True\n        }\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"86-environment-validation-and-quality-assurance",children:"8.6 Environment Validation and Quality Assurance"}),"\n",(0,t.jsx)(e.h3,{id:"861-validation-metrics",children:"8.6.1 Validation Metrics"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Metrics for validating simulation environments\nenvironment_validation_metrics = {\n    "visual_validation": {\n        "photorealism_score": {\n            "metric": "LPIPS",  # Learned Perceptual Image Patch Similarity\n            "threshold": 0.3,   # Acceptable difference from real images\n            "benchmark": "real_world_dataset"\n        },\n        "geometric_accuracy": {\n            "metric": "point_cloud_registration_error",\n            "threshold_cm": 5.0,  # Centimeters\n            "benchmark": "lidar_scan_of_real_env"\n        },\n        "lighting_match": {\n            "metric": "histogram_comparison",\n            "threshold": 0.1,   # Acceptable histogram difference\n            "benchmark": "hdr_image_of_real_env"\n        }\n    },\n    "physical_validation": {\n        "dynamics_match": {\n            "metric": "trajectory_deviation",\n            "threshold_cm": 10.0,\n            "benchmark": "real_robot_trajectory"\n        },\n        "contact_modeling": {\n            "metric": "contact_force_correlation",\n            "threshold": 0.8,   # Correlation coefficient\n            "benchmark": "force_plate_measurements"\n        },\n        "locomotion_validation": {\n            "metric": "walking_stability_comparison",\n            "threshold": 0.95,  # Success rate comparison\n            "benchmark": "real_robot_locomotion_data"\n        }\n    },\n    "sensor_validation": {\n        "camera_validation": {\n            "metric": "feature_matching_score",\n            "threshold": 0.7,\n            "benchmark": "real_camera_data"\n        },\n        "imu_validation": {\n            "metric": "orientation_drift_comparison",\n            "threshold_degrees": 5.0,\n            "benchmark": "real_imu_data"\n        },\n        "depth_validation": {\n            "metric": "depth_accuracy_rmse",\n            "threshold_cm": 10.0,\n            "benchmark": "real_depth_sensor_data"\n        }\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"862-automated-testing-framework",children:"8.6.2 Automated Testing Framework"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Automated testing framework for environment validation\nclass EnvironmentValidationFramework:\n    """Framework for validating simulation environments"""\n\n    def __init__(self, metrics_config):\n        self.metrics_config = metrics_config\n        self.test_results = {}\n\n    def run_visual_validation_tests(self, sim_env, real_data):\n        """Run visual validation tests"""\n        results = {}\n\n        # Photorealism test\n        results["photorealism"] = self._test_photorealism(sim_env, real_data)\n\n        # Geometric accuracy test\n        results["geometric_accuracy"] = self._test_geometric_accuracy(sim_env, real_data)\n\n        # Lighting validation\n        results["lighting_match"] = self._test_lighting_match(sim_env, real_data)\n\n        self.test_results["visual"] = results\n        return results\n\n    def run_physical_validation_tests(self, sim_env, real_robot_data):\n        """Run physical validation tests"""\n        results = {}\n\n        # Dynamics validation\n        results["dynamics_match"] = self._test_dynamics_match(sim_env, real_robot_data)\n\n        # Contact modeling validation\n        results["contact_modeling"] = self._test_contact_modeling(sim_env, real_robot_data)\n\n        # Locomotion validation\n        results["locomotion"] = self._test_locomotion_validation(sim_env, real_robot_data)\n\n        self.test_results["physical"] = results\n        return results\n\n    def run_sensor_validation_tests(self, sim_env, real_sensor_data):\n        """Run sensor validation tests"""\n        results = {}\n\n        # Camera validation\n        results["camera"] = self._test_camera_validation(sim_env, real_sensor_data)\n\n        # IMU validation\n        results["imu"] = self._test_imu_validation(sim_env, real_sensor_data)\n\n        # Depth sensor validation\n        results["depth"] = self._test_depth_validation(sim_env, real_sensor_data)\n\n        self.test_results["sensor"] = results\n        return results\n\n    def generate_validation_report(self):\n        """Generate comprehensive validation report"""\n        report = {\n            "timestamp": str(datetime.now()),\n            "environment_config": self._get_environment_config(),\n            "validation_results": self.test_results,\n            "overall_score": self._calculate_overall_score(),\n            "recommendations": self._generate_recommendations()\n        }\n\n        return report\n\n    def _test_photorealism(self, sim_env, real_data):\n        """Test photorealism of simulation"""\n        # Calculate LPIPS score between sim and real images\n        pass\n\n    def _test_geometric_accuracy(self, sim_env, real_data):\n        """Test geometric accuracy of environment"""\n        # Compare point clouds from sim and real\n        pass\n\n    def _test_lighting_match(self, sim_env, real_data):\n        """Test lighting similarity"""\n        # Compare lighting conditions\n        pass\n\n    def _test_dynamics_match(self, sim_env, real_robot_data):\n        """Test dynamics similarity"""\n        # Compare robot trajectories in sim vs real\n        pass\n\n    def _calculate_overall_score(self):\n        """Calculate overall validation score"""\n        # Aggregate all validation results\n        pass\n\n    def _generate_recommendations(self):\n        """Generate recommendations based on validation results"""\n        # Provide suggestions for environment improvements\n        pass\n'})}),"\n",(0,t.jsx)(e.h2,{id:"87-performance-optimization",children:"8.7 Performance Optimization"}),"\n",(0,t.jsx)(e.h3,{id:"871-rendering-optimization",children:"8.7.1 Rendering Optimization"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Rendering optimization settings for high-fidelity environments\nrendering_optimization_config = {\n    "level_of_detail": {\n        "distance_based_lod": True,\n        "lod_distance_thresholds": [5.0, 10.0, 20.0],  # Meters\n        "detail_reduction_factors": [0.5, 0.25, 0.1]   # Reduce detail by factor\n    },\n    "culling_techniques": {\n        "frustum_culling": True,\n        "occlusion_culling": True,\n        "distance_culling": True,\n        "cull_distance": 50.0  # Meters\n    },\n    "rendering_quality": {\n        "real_time_training": {\n            "resolution_scale": 0.5,      # Train at lower resolution\n            "shadows": "low",             # Low quality shadows\n            "reflections": False,         # Disable reflections\n            "post_processing": "minimal"  # Minimal post-processing\n        },\n        "evaluation_rendering": {\n            "resolution_scale": 1.0,      # Full resolution for eval\n            "shadows": "high",            # High quality shadows\n            "reflections": "realistic",   # Realistic reflections\n            "post_processing": "full"     # Full post-processing\n        }\n    },\n    "multi_gpu_rendering": {\n        "render_instance_distribution": True,\n        "load_balancing": "adaptive",\n        "synchronization": "temporal"\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"872-physics-optimization",children:"8.7.2 Physics Optimization"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Physics optimization settings\nphysics_optimization_config = {\n    "solver_optimization": {\n        "solver_type": "TGS",           # TGS or PBD\n        "iterations": {\n            "position": 4,              # Position solver iterations\n            "velocity": 2,              # Velocity solver iterations\n            "warm_start": True          # Use warm start for stability\n        },\n        "substepping": {\n            "enabled": True,\n            "max_substeps": 8,\n            "adaptivity_threshold": 0.1  # Adjust substeps based on contacts\n        }\n    },\n    "collision_optimization": {\n        "broad_phase_algorithm": "multibox",\n        "narrow_phase_algorithm": "hybrid",\n        "pair_cache_size": 8192,\n        "contact_manifold_cache": True\n    },\n    "decomposition": {\n        "convex_decomposition": True,\n        "max_convex_hulls": 16,\n        "decomposition_quality": "medium"  # low, medium, high\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"88-integration-with-isaac-sim",children:"8.8 Integration with Isaac Sim"}),"\n",(0,t.jsx)(e.h3,{id:"881-environment-loading-and-management",children:"8.8.1 Environment Loading and Management"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Environment loading and management system\nclass EnvironmentManager:\n    """Manage loading and switching between environments"""\n\n    def __init__(self):\n        self.loaded_environments = {}\n        self.active_environment = None\n        self.environment_registry = self._initialize_registry()\n\n    def _initialize_registry(self):\n        """Initialize environment registry"""\n        return {\n            "home_simple": "/Isaac/Environments/Home/home_simple.usd",\n            "office_simple": "/Isaac/Environments/Office/office_simple.usd",\n            "warehouse": "/Isaac/Environments/Industrial/warehouse.usd",\n            "outdoor_park": "/Isaac/Environments/Outdoor/park.usd"\n        }\n\n    def load_environment(self, env_name, config=None):\n        """Load specified environment"""\n        if env_name not in self.environment_registry:\n            raise ValueError(f"Unknown environment: {env_name}")\n\n        usd_path = self.environment_registry[env_name]\n\n        # Load environment from USD\n        stage = omni.usd.get_context().get_stage()\n        env_prim = stage.OverridePrim(Sdf.Path(f"/World/{env_name}"))\n        env_prim.GetReferences().AddReference(usd_path)\n\n        # Store in loaded environments\n        self.loaded_environments[env_name] = {\n            "prim": env_prim,\n            "config": config,\n            "loaded": True\n        }\n\n        return env_prim\n\n    def switch_environment(self, env_name):\n        """Switch to specified environment"""\n        if env_name not in self.loaded_environments:\n            self.load_environment(env_name)\n\n        # Activate the environment\n        if self.active_environment:\n            # Deactivate current environment\n            self._deactivate_environment(self.active_environment)\n\n        # Activate new environment\n        self.active_environment = env_name\n        self._activate_environment(env_name)\n\n    def add_dynamic_elements(self, env_name, elements_config):\n        """Add dynamic elements to environment"""\n        if env_name not in self.loaded_environments:\n            raise ValueError(f"Environment {env_name} not loaded")\n\n        # Add dynamic elements based on configuration\n        for element in elements_config:\n            self._add_dynamic_element(env_name, element)\n\n    def _deactivate_environment(self, env_name):\n        """Deactivate current environment"""\n        # Implementation would hide/disable current environment\n        pass\n\n    def _activate_environment(self, env_name):\n        """Activate specified environment"""\n        # Implementation would show/enable environment\n        pass\n\n    def _add_dynamic_element(self, env_name, element_config):\n        """Add a dynamic element to the environment"""\n        # Add dynamic objects, change lighting, etc.\n        pass\n'})}),"\n",(0,t.jsx)(e.h3,{id:"882-sensor-integration",children:"8.8.2 Sensor Integration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Sensor integration with environments\nclass SensorIntegrationManager:\n    """Manage sensor integration with environments"""\n\n    def __init__(self, environment_manager):\n        self.env_manager = environment_manager\n        self.attached_sensors = {}\n\n    def attach_sensors_to_robot(self, robot_prim_path, sensor_configs):\n        """Attach sensors to robot in environment"""\n        for sensor_name, config in sensor_configs.items():\n            sensor_prim_path = f"{robot_prim_path}/Sensors/{sensor_name}"\n\n            if config["type"] == "camera":\n                sensor = self._create_camera_sensor(sensor_prim_path, config)\n            elif config["type"] == "imu":\n                sensor = self._create_imu_sensor(sensor_prim_path, config)\n            elif config["type"] == "lidar":\n                sensor = self._create_lidar_sensor(sensor_prim_path, config)\n            else:\n                raise ValueError(f"Unsupported sensor type: {config[\'type\']}")\n\n            # Store sensor reference\n            self.attached_sensors[sensor_name] = {\n                "sensor": sensor,\n                "config": config,\n                "attached_to": robot_prim_path\n            }\n\n    def _create_camera_sensor(self, prim_path, config):\n        """Create camera sensor"""\n        from omni.isaac.sensor import Camera\n        camera = Camera(\n            prim_path=prim_path,\n            frequency=config.get("frequency", 30),\n            resolution=config.get("resolution", [640, 480])\n        )\n\n        # Apply noise and distortion if specified\n        if "noise" in config:\n            camera.add_noise_params(**config["noise"])\n        if "distortion" in config:\n            camera.set_distortion_params(**config["distortion"])\n\n        return camera\n\n    def _create_imu_sensor(self, prim_path, config):\n        """Create IMU sensor"""\n        from omni.isaac.sensor import IMU\n        imu = IMU(\n            prim_path=prim_path,\n            frequency=config.get("frequency", 100)\n        )\n\n        # Apply noise parameters if specified\n        if "noise_params" in config:\n            imu.set_noise_params(**config["noise_params"])\n\n        return imu\n\n    def _create_lidar_sensor(self, prim_path, config):\n        """Create LiDAR sensor"""\n        from omni.isaac.sensor import LidarRtx\n        lidar = LidarRtx(\n            prim_path=prim_path,\n            translation=config.get("position", [0.0, 0.0, 0.0]),\n            orientation=config.get("rotation", [0.0, 0.0, 0.0, 1.0]),\n            config_file_name=config.get("config_file", "Example_Rotary")\n        )\n\n        return lidar\n'})}),"\n",(0,t.jsx)(e.h2,{id:"89-summary",children:"8.9 Summary"}),"\n",(0,t.jsx)(e.p,{children:"Creating high-fidelity environments and sensor simulations is critical for effective humanoid robotics development in simulation. Key aspects include:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Visual Fidelity"}),": Photorealistic rendering with accurate materials and lighting"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Physical Accuracy"}),": Realistic physics modeling with appropriate parameters"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Sensor Simulation"}),": Accurate modeling of real sensor characteristics and noise"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Domain Randomization"}),": Techniques to improve sim-to-real transfer"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Environment Diversity"}),": Creating varied environments that match deployment scenarios"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Validation"}),": Ensuring simulation environments match real-world conditions"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Performance"}),": Optimizing for both training efficiency and accuracy"]}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"The combination of high-fidelity visual and physical simulation with realistic sensor models enables the development of humanoid robots that can successfully transition from simulation to real-world deployment."}),"\n",(0,t.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Create a home environment with realistic furniture and lighting in Isaac Sim."}),"\n",(0,t.jsx)(e.li,{children:"Implement domain randomization for visual appearance and physics parameters."}),"\n",(0,t.jsx)(e.li,{children:"Add a humanoid robot to the environment and configure its sensors."}),"\n",(0,t.jsx)(e.li,{children:"Validate the environment by comparing simulation results with real-world data."}),"\n",(0,t.jsx)(e.li,{children:"Optimize the environment for real-time performance while maintaining fidelity."}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"references",children:"References"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"NVIDIA Isaac Sim Documentation. (2024). NVIDIA Corporation."}),"\n",(0,t.jsx)(e.li,{children:'Peng, X.B., et al. (2018). "Sim-to-real transfer of robotic control with dynamics randomization."'}),"\n",(0,t.jsx)(e.li,{children:'Sadeghi, F., & Levine, S. (2017). "CAD2RL: Real single-image flight without a single real image."'}),"\n",(0,t.jsx)(e.li,{children:'James, S., et al. (2019). "Sim-to-real via sim-to-sim: Data-efficient robotic grasping via randomized-to-canonical adaptation networks."'}),"\n"]})]})}function m(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>s});var t=i(6540);const a={},r=t.createContext(a);function o(n){const e=t.useContext(r);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),t.createElement(r.Provider,{value:e},n.children)}}}]);